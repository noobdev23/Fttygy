
<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>AI Eye Scanner with Sound</title>
<style>
  body { background:#000; margin:0; display:flex; flex-direction:column; align-items:center; color:white; font-family:sans-serif; padding-bottom:60px; }
  video { width:100%; max-width:600px; border:3px solid #0f0; border-radius:10px; margin-top:10px; }
  #score { font-size:24px; margin-top:10px; }
  #error { color:red; margin-top:10px; }
  footer {
    position:fixed;
    bottom:0; left:0; right:0;
    background:rgba(20,20,20,0.9);
    border-top:1px solid rgba(255,255,255,0.1);
    text-align:center;
    padding:10px;
    font-size:14px;
    color:#ccc;
    backdrop-filter: blur(6px);
    box-shadow:0 -2px 10px rgba(0,255,0,0.2);
  }
  footer strong { color:#3ddc97; }
</style>
</head>
<body>
<h1>AI Eye Scanner</h1>
<video id="video" autoplay playsinline></video>
<div id="score">Eye Score: --</div>
<div id="error"></div>

<audio id="scannerSound" preload="auto">
<source src="https://actions.google.com/sounds/v1/alarms/beep_short.ogg" type="audio/ogg">
</audio>

<footer>
  <strong>Tip:</strong> Make sure you are in good lighting for better accuracy.
</footer>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.13.0"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
<script>
const video = document.getElementById('video');
const scoreDisplay = document.getElementById('score');
const errorDisplay = document.getElementById('error');
const scannerSound = document.getElementById('scannerSound');

async function initCamera() {
    try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
        detectEyes();
    } catch (err) {
        errorDisplay.textContent = 'Camera error: ' + err.message;
    }
}

async function detectEyes() {
    const model = await blazeface.load();
    while (true) {
        const predictions = await model.estimateFaces(video, false);
        if (predictions.length > 0) {
            scannerSound.play().catch(() => {});
            let openness = 0;
            predictions.forEach(pred => {
                openness += pred.landmarks.length;
            });
            let score = Math.min(100, Math.floor(openness * 5));
            scoreDisplay.textContent = 'Eye Score: ' + score;
        } else {
            scoreDisplay.textContent = 'Eye Score: --';
        }
        await new Promise(r => setTimeout(r, 500));
    }
}

initCamera();
</script>
</body>
</html>
